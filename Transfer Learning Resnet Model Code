import pandas as pd
import os
import numpy as np
from pathlib import Path
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import random
import warnings
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')
import gc
gc.enable()
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image_dataset_from_directory

cfg = {
    'train_path': r"C:\Users\User\Downloads\New_Project\Traning\train_images",
    'train_df_path': r'C:\Users\User\Downloads\New_Project\Traning\train.csv',
    'img_size': (224, 224),
    'epochs': 30,
    'num_workers': 16,
    'lr': 1e-03,
    'batch_size': 16,
    'device': 'cuda',
    'lr_values': [1e-2, 2e-2, 1e-3, 2e-3, 1e-4, 2e-4]
}

def create_datasets():
    full_ds = image_dataset_from_directory(
        cfg['train_path'],
        seed=123,
        image_size=cfg['img_size'],
        batch_size=cfg['batch_size'],
        shuffle=True
    )
    total_batches = tf.data.experimental.cardinality(full_ds).numpy()
    train_batches = int(0.7 * total_batches)
    val_batches = int(0.15 * total_batches)
    train_ds = full_ds.take(train_batches)
    val_ds = full_ds.skip(train_batches).take(val_batches)
    test_ds = full_ds.skip(train_batches + val_batches)
    train_ds = train_ds.prefetch(tf.data.AUTOTUNE)
    val_ds = val_ds.prefetch(tf.data.AUTOTUNE)
    test_ds = test_ds.prefetch(tf.data.AUTOTUNE)
    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = create_datasets()
# Found 11949 files belonging to 13 classes.

model = Sequential([
    preprocessing.RandomFlip('horizontal'),
    preprocessing.RandomContrast(0.1, seed=0),
    preprocessing.RandomRotation(0.25, seed=0),
    preprocessing.RandomZoom(height_factor=0.2, width_factor=0.1, seed=0),
    preprocessing.RandomFlip('vertical'),
    keras.applications.InceptionResNetV2(
        include_top=False,
        weights='imagenet',
        input_shape=(cfg['img_size'][0], cfg['img_size'][1], 3)
    ),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Flatten(),
    keras.layers.Dense(256, activation='relu',
                         bias_regularizer=keras.regularizers.L1L2(l1=0.01, l2=0.00)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(13, activation='softmax')
])
model.build(input_shape=(None, cfg['img_size'][0], cfg['img_size'][1], 3))
model.summary()

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=cfg['lr']),
    loss=keras.losses.SparseCategoricalCrossentropy(),
    metrics=['accuracy']
)

es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)
checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    batch_size=cfg['batch_size'],
    epochs=cfg['epochs'],
    callbacks=[es, reduce_lr, checkpoint],
    shuffle=True,
    verbose=1
)

test_data_set = model.evaluate(test_ds)
print(test_data_set)

print(history)
print(history.params)
print(history.history.keys())
print(history.history['accuracy'])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

for test_batch, lable_batch in test_ds.take(1):
    print(test_batch[0].numpy())
    plt.figure(figsize=(5, 5))
    plt.imshow(test_batch[0].numpy().astype("uint8"))
    plt.show()

for test_batch, lable_batch in test_ds.take(1):
    lst_image = test_batch[0].numpy().astype("uint8")
    lst_lable = lable_batch[0].numpy()
    print("Try Shuffle image to predict =")
    print("Real class number = ", lst_lable)
    print("Real class name = ", class_names[lst_lable])
    plt.imshow(lst_image)
    plt.show()
    test_batch_prediction = model.predict(test_batch)
    print(test_batch_prediction[0])
    print("prediction class number =", np.argmax(test_batch_prediction[0]))
    print("prediction class name =", class_names[np.argmax(test_batch_prediction[0])])

plt.figure(figsize=(15, 15))
Collect_Test_images_list = []
Collect_Test_labels_list = []
for test_data, label_test_data in test_ds.take(6):
    Collect_Test_images_list.extend(test_data.numpy())
    Collect_Test_labels_list.extend(label_test_data.numpy())
Collect_Test_images_to_array = np.array(Collect_Test_images_list)
Collect_Test_labels_to_array = np.array(Collect_Test_labels_list)
predictions = model.predict(Collect_Test_images_to_array)
for i in range(16):
    ax = plt.subplot(4, 4, i + 1)
    actual_class = class_names[Collect_Test_labels_to_array[i]]
    prediction_class = class_names[np.argmax(predictions[i])]
    confidence = round(100 * np.max(predictions[i]), 2)
    plt.imshow(Collect_Test_images_to_array[i].astype("uint8"))
    plt.title(f"Actual: {actual_class}\nPredicted: {prediction_class}\nConfidence: {confidence}%", fontsize=12)
    plt.axis("off")
plt.tight_layout()
plt.show()

y_true = []
y_pred = []
for test_batch, label_batch in test_ds:
    preds = model.predict(test_batch)
    y_true.extend(label_batch.numpy())
    y_pred.extend(np.argmax(preds, axis=1))
y_true = np.array(y_true)
y_pred = np.array(y_pred)

cm = tf.math.confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix")
plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.show()

from sklearn.metrics import classification_report
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
report_dict = {key: value for key, value in report.items() if key in class_names}
precision = [report_dict[c]['precision'] for c in class_names]
recall = [report_dict[c]['recall'] for c in class_names]
f1_score = [report_dict[c]['f1-score'] for c in class_names]
x = np.arange(len(class_names))
width = 0.25
plt.figure(figsize=(12, 6))
plt.bar(x - width, precision, width, label='Precision', color='skyblue')
plt.bar(x, recall, width, label='Recall', color='salmon')
plt.bar(x + width, f1_score, width, label='F1-Score', color='lightgreen')
plt.xticks(x, class_names, rotation=45, ha='right')
plt.ylim([0, 1])
plt.title("Classification Report Metrics by Class")
plt.xlabel("Class")
plt.ylabel("Score")
plt.legend()
plt.tight_layout()
plt.show()

model.save('best_final_model.h5')
import os
from IPython.display import FileLink
os.chdir(r'C:\Users\User\Downloads\New_Project\Traning\Model')
print(FileLink(r'best_final_model.h5'))
